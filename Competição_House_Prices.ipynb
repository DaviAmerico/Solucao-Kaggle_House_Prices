{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Competição House Prices.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1Q9LEIUApzLGhkjuJK_P1pzMoEnf0MWs4",
      "authorship_tag": "ABX9TyOghhtTRDeHRg8XpXwsDULM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaviAmerico/project1/blob/main/Competi%C3%A7%C3%A3o_House_Prices.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOwZqfogMCc6"
      },
      "source": [
        "# Resolução da competição House Prices - Advanced Regression Techniques\r\n",
        "Nosso objetivo aqui é criar um modelo que preveja os valores de determinadas casas com base em 80 variáveis explicativas, iremos fazer isso usando um modelo de regressão.A resolução dessa competição se dará em três tópicos: **Limpeza dos dados**,**Transformando os dados** e **Criando o modelo e prevendo os preços**.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y15uZZ-FQlsc"
      },
      "source": [
        "**Limpeza dos dados**:\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tqdTjkcciwt"
      },
      "source": [
        "Nessa seção iremos tratar os dados faltantes (*nan's*), mas antes vamos importar os dados a serem usados:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0PvyEhiR6xs"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from scipy import stats\r\n",
        "import xgboost as xgb\r\n",
        "from sklearn.model_selection import RandomizedSearchCV\r\n",
        "#importando dados para um pandas dataframe \r\n",
        "train=pd.read_csv('/content/drive/MyDrive/train.csv')\r\n",
        "test=pd.read_csv('/content/drive/MyDrive/test.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3wOBPUhevjr"
      },
      "source": [
        "O conjunto de dados *train* se refere aos dados a serem usados para a construção do modelo, já o conjunto *test* é aonde iremos fazer as previsões."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwoE1yJB6gWK"
      },
      "source": [
        "Antes de analisarmos a existência de *nan's* vamos dar uma olhada nos dois conjuntos de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnvItOu66qma",
        "outputId": "85af1f41-7f27-40f6-fdff-e44785d6a483"
      },
      "source": [
        "print(train.head())\r\n",
        "print(test.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Id  MSSubClass MSZoning  ...  SaleType  SaleCondition SalePrice\n",
            "0   1          60       RL  ...        WD         Normal    208500\n",
            "1   2          20       RL  ...        WD         Normal    181500\n",
            "2   3          60       RL  ...        WD         Normal    223500\n",
            "3   4          70       RL  ...        WD        Abnorml    140000\n",
            "4   5          60       RL  ...        WD         Normal    250000\n",
            "\n",
            "[5 rows x 81 columns]\n",
            "     Id  MSSubClass MSZoning  ...  YrSold  SaleType SaleCondition\n",
            "0  1461          20       RH  ...    2010        WD        Normal\n",
            "1  1462          20       RL  ...    2010        WD        Normal\n",
            "2  1463          60       RL  ...    2010        WD        Normal\n",
            "3  1464          60       RL  ...    2010        WD        Normal\n",
            "4  1465         120       RL  ...    2010        WD        Normal\n",
            "\n",
            "[5 rows x 80 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0UPjZ0jSvwF"
      },
      "source": [
        "Percebe-se que *test* não tem os preços de venda das casas (*SalePrice*) , pois como já dito , usaremos esse conjunto para realizar as previsões,uma vez que criarmos o modelo.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXbjnBRF7llA"
      },
      "source": [
        "Agora vamos verificar a existência de valores faltantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZbh6jVETHPO",
        "outputId": "a391892b-5416-41fb-9df3-9a0bac2f9720"
      },
      "source": [
        "print(train.isna().sum().sum())\r\n",
        "print(test.isna().sum().sum())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6965\n",
            "7000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RT9vjfKgUnPY"
      },
      "source": [
        "No conjunto *train* temos 6965 valores faltantes e no conjunto *test* temos 7000.Inicialmente vamos tratar os *nan's* nas colunas númericas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf7Wqz_pVVbp"
      },
      "source": [
        "train.fillna(train.mean(),inplace=True)\r\n",
        "test.fillna(test.mean(),inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HyJpx-HVnfO"
      },
      "source": [
        "Acima substituimos os valores faltantes das colunas númericas pela média dos valores em cada coluna.Pelo fato de termos usado a média as colunas categóricas não foram alteradas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7g_qfkrW9xo"
      },
      "source": [
        "Agora vamos tratar os *nan's* de colunas categóricas, infelizmente isso não é tão simples quanto para os *nan's* númericos ,portanto teremos que usar uma recursividade para substituí-los:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfU7qqELW_Oz"
      },
      "source": [
        "for i in train.select_dtypes('object').columns:\r\n",
        "    train.loc[:,i].fillna(train.loc[:,i].value_counts().index[0],inplace=True)\r\n",
        "    test.loc[:,i].fillna(test.loc[:,i].value_counts().index[0],inplace=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usWZG3_VXDXp"
      },
      "source": [
        "Acima estamos percorrendo *i* nas colunas categóricas dos dados , para cada coluna os *nan's* serão substituidos pela categoria mais frequente da respectiva coluna."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OA6c55M3XqnD"
      },
      "source": [
        "Podemos ver então que não existem mais valores faltantes nos dois conjuntos de dados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWJzkQngXxV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40aed7bc-4c1e-403e-c59c-dc3809af6558"
      },
      "source": [
        "print(train.isna().sum().sum())\r\n",
        "print(test.isna().sum().sum())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfOg8uRgYKUV"
      },
      "source": [
        "**Transformando os dados:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y8ACLHYYVGE"
      },
      "source": [
        "A maioria dos algoritmos de aprendizado de maquina só aceitam dados númericos e funcionam melhor com dados normalizados.Abaixo vamos transformar todas categorias em números:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmg0txHJY81u"
      },
      "source": [
        "for i in train.select_dtypes('object').columns:\r\n",
        "    train.loc[:,i]=LabelEncoder().fit_transform(train.loc[:,i].astype('str'))\r\n",
        "    test.loc[:,i]=LabelEncoder().fit_transform(test.loc[:,i].astype('str'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uKnZe9FZDjy"
      },
      "source": [
        "Podemos ver agora que cada coluna dos dois conjuntos é númerica:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zezmT_FZKkq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af3aa8c-504f-40fb-f41f-5d2697ec50fd"
      },
      "source": [
        "print(train.dtypes,\"\\n\",\"\\n\",\"\\n\")\r\n",
        "print(test.dtypes)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id                 int64\n",
            "MSSubClass         int64\n",
            "MSZoning           int64\n",
            "LotFrontage      float64\n",
            "LotArea            int64\n",
            "                  ...   \n",
            "MoSold             int64\n",
            "YrSold             int64\n",
            "SaleType           int64\n",
            "SaleCondition      int64\n",
            "SalePrice          int64\n",
            "Length: 81, dtype: object \n",
            " \n",
            " \n",
            "\n",
            "Id                 int64\n",
            "MSSubClass         int64\n",
            "MSZoning           int64\n",
            "LotFrontage      float64\n",
            "LotArea            int64\n",
            "                  ...   \n",
            "MiscVal            int64\n",
            "MoSold             int64\n",
            "YrSold             int64\n",
            "SaleType           int64\n",
            "SaleCondition      int64\n",
            "Length: 80, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XsLj6UdZXRY"
      },
      "source": [
        "Antes de normalizar os dados vamos separar a variável resposta das explicativas , pois estamos interessados em apenas normalizar as explicativas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf60bt6KaI4S"
      },
      "source": [
        "xt=train.iloc[:,0:80]\r\n",
        "yt=train.iloc[:,80]\r\n",
        "xte=test\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAwWRX9RaUNd"
      },
      "source": [
        "Em *xt* e *xte* temos as variáveis explicativas a serem normalizadas nos conjuntos *train* e *test*, note que *xte* é igual a *test*,pois, o conjunto de dados *test* não contém observações da variável resposta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6aq7DL1jULC"
      },
      "source": [
        "Normalizando os dados, exceto a resposta, temos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kT2jgakbYlb"
      },
      "source": [
        "zt=pd.DataFrame(StandardScaler().fit_transform(xt))\r\n",
        "zt.columns=xt.columns\r\n",
        "zte=pd.DataFrame(StandardScaler().fit_transform(xte))\r\n",
        "zte.columns=xte.columns"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDrPejP9bs3E"
      },
      "source": [
        "*zt* e *zte* são os preditores normalizados para ambos os conjuntos de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfd8WBu8b-_z"
      },
      "source": [
        "Agora estamos preparados para criar nosso modelo e realizar as predições :D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEHnqC-zcDmA"
      },
      "source": [
        "**Criando o modelo e prevendo os preços:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykRSNobLcmO4"
      },
      "source": [
        "O modelo a ser usado para resolver o problema de regressão é o *XGBoosting  (Extreme Gradient Boosting)*, ele será treinado em *(zt,yt)*.Aqui iremos testar várias combinações aleatórias de hiper-parâmetros no modelo e pegar a combinação ótima depois de um determinado número de tentativas, no caso são 25 tentativas, para nós a combinação ótima é aquela que obteve a menor raiz do erro quadrático logarítmico médio,métrica de avaliação usada na competição, dentro da validação cruzada com 5 *folds*, então:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ewJngocd0g6"
      },
      "source": [
        "xgbr=xgb.XGBRegressor()\r\n",
        "param_grid = {'n_estimators': stats.randint(150, 500),\r\n",
        "              'learning_rate': stats.uniform(0.01, 0.07),\r\n",
        "              'subsample': stats.uniform(0.3, 0.7),\r\n",
        "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\r\n",
        "              'colsample_bytree': stats.uniform(0.45,0.5),\r\n",
        "              'min_child_weight': [1, 2, 3]\r\n",
        "             }\r\n",
        "f=RandomizedSearchCV(xgbr,param_grid,cv=5,n_iter=25,scoring='neg_mean_squared_log_error')\r\n",
        "f.fit(zt,yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCbZcWs_eK6c"
      },
      "source": [
        "Podemos, também, verificar o erro da melhor combinação de hiper-parâmetros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwAuyllJfYFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19baff3a-ad05-41ac-c80b-153e6669d857"
      },
      "source": [
        "bs=np.sqrt(-f.best_score_)\r\n",
        "print(bs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.12426714375527574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaUmfhGtfhX7"
      },
      "source": [
        "Agora podemos fazer a previsão dos preços das casas dentro do conjunto *test* normalizado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeoHjkYRf07b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0fd9c1e-4809-4fc0-a009-bb46b882efab"
      },
      "source": [
        "yp=f.best_estimator_.predict(zte)\r\n",
        "print(yp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[129399.016 153070.3   187078.2   ... 174546.45  121318.96  250490.44 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVZ24bDhl6el"
      },
      "source": [
        "Agora basta exportar as predições para o Kaggle para concluir a competição :D"
      ]
    }
  ]
}